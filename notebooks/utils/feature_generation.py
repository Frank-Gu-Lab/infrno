# -*- coding: utf-8 -*-
"""
Custom scripts to generate DISCO modelling features: cohort chemical shift fingerprints, 
extracting molecular weight from polymer name string.
"""
import pandas as pd
import numpy as np
from sklearn import preprocessing


def generate_ppm_bins(df):
    ''' Based on the range of ppm values in dataset, this function generates bins and appends new Categorical columns for ppm_bins and binding labels
    to the dataframe to better generalize characteristic binding for ML purposes.
    
    Parameters
    ----------
    df : Pandas.DataFrame
        Dataframe containing ppm measurements, one row per proton.

    Returns
    -------
    df : Pandas.Dataframe
        containing ppm bin column
    '''
    # assign ppm values consistent for each polymer (ensure consistent zipcode)
    df = assign_mean_ppms(df)

    ppm_raw = df.ppm.values

    max_ppm = np.max(ppm_raw)  # define the range of ppm values in dataset

    # define bin ranges to bound that data
    ppm_bins_1 = np.arange(0, max_ppm+0.1, 0.1)
    ppm_bins_2 = ppm_bins_1[1:]

    ppm_bins_tuples = [*zip(np.round(ppm_bins_1, decimals=1), np.round(ppm_bins_2, decimals=1))]
    bins = pd.IntervalIndex.from_tuples(ppm_bins_tuples)  # convert the ranges into bins

    # apply bins to dataset
    df.insert(loc=3, column="ppm_bin", value=pd.cut(ppm_raw, bins, ordered=True))

    # sort dataset by ppm_bin
    df = df.sort_values(by=["ppm_bin"], ascending=False).reset_index(drop=True)

    return df


def generate_categorical(df, col_name):
    '''Generates categorical variable from column name.
    
    Parameters
    ----------
    df : Pandas.DataFrame
        Dataframe containing at least one column of strings to be categorized.

    Returns
    -------
    df : Pandas.Dataframe
        containing categorized column version

    '''

    df[col_name] = pd.Categorical(df[col_name].values, ordered=False)

    return df


def generate_polymer_zip_codes(dataset, kind=None):
    ''' Polymer Zip Codes are generated by identifying which proton observations share membership to a polymer_name,
    and then generating a "zip code" comprised of the numeric encodings of the ppm_bin memberships in that same group. 
    
    Parameters
    ----------
    dataset : Pandas.DataFrame
        This function receives a dataset of this structure:
        * Each Row = One Proton Observation
        * Has a ppm_bin column (as generated by bin_ppms function)
        * Has a polymer_name column (also generated per above function)
        * Other columns are OK to exist too but will not be required for features in ML.

    kind : string {"zipcode","cohort"} 
        * cohort mode excludes the sample proton from zipcode, 
        which is used to generate the cohort fingerprint downstream


    Returns
    -------
    dataset : Pandas.DataFrame
        The same dataset, with a polymer_zip_code column 
    
    ppm_bin_conversion_dict : dict, {code : ppm_bin}
        Dictionary mapping ppm_bin to index (ppm_bin code).
    
    polymer_name_conversion_dict : dict, {code : polymer_name}
        Dictionary mapping polymer_name to index (polymer_name code).
        
    '''

    # get list of all ppm bins/polymer names
    ppm_bin_list = dataset.ppm_bin.cat.categories
    polymer_name_list = dataset.polymer_name.cat.categories

    # instantiate LabelEncoder objects to convert identifying strings to labels
    le_bins = preprocessing.LabelEncoder()
    le_polymer_names = preprocessing.LabelEncoder()

    # fit label encocders to the ppm bin and polymer name categories, and transform list to copy of all encoded labels
    ppm_bin_codes = le_bins.fit_transform(ppm_bin_list)
    polymer_name_codes = le_polymer_names.fit_transform(polymer_name_list)

    # transform the dataset columns in the same way
    ppm_bin_code_col = le_bins.transform(dataset.ppm_bin)
    polymer_name_code_col = le_polymer_names.transform(dataset.polymer_name)

    # add transformed columns to the parent dataset
    dataset["ppm_bin_codes"] = ppm_bin_code_col
    dataset["polymer_name_codes"] = polymer_name_code_col

    # create dictionaries to go back and forth btw codes and categories
    ppm_bin_conversion_dict = dict(zip(ppm_bin_codes, ppm_bin_list))
    polymer_name_conversion_dict = dict(zip(polymer_name_codes, polymer_name_list))

    # Generate the polymer zip code for each observation
    for i in dataset.index:  
        row_i = dataset[dataset.index == i]

        # identify associated ppm bin cateory and polymer name
        row_ppm_bin = ppm_bin_code_col[i]
        row_polymer_name = polymer_name_code_col[i]

        # determine all other observations that match this pairing and subset
        match_mask_exact = np.where(np.logical_and(dataset.ppm_bin_codes == row_ppm_bin, dataset.polymer_name_codes == row_polymer_name))
        match_mask_exact = match_mask_exact[0]

        if kind == "cohort":
            # determine neighbours-only group matches and subset
            all_mask_group = np.where(
                dataset.polymer_name_codes == row_polymer_name)[0]
            all_match_group_subset = dataset.iloc[all_mask_group, :]
            neighbour_mask_group = np.where(np.logical_and(dataset.polymer_name_codes == row_polymer_name, dataset.ppm_bin_codes != row_ppm_bin))[0]
            neighbour_group_subset = dataset.iloc[neighbour_mask_group, :]

            # else:
            # find all unique combos of ppm bins within subset
            subset_unique_bin_codes = str(neighbour_group_subset.ppm_bin_codes.unique())
            zipcode = subset_unique_bin_codes

            # assign that neighbour zipcode to all replicates of this proton from this polymer
            dataset.loc[np.where(np.logical_and(dataset.polymer_name_codes == row_polymer_name,
                                 dataset.ppm_bin_codes == row_ppm_bin))[0], ("polymer_zip_code")] = zipcode

        else:
            # determine proton-inclusive group matches and subset
            match_mask_group = np.where(
                dataset.polymer_name_codes == row_polymer_name)
            match_mask_group = match_mask_group[0]
            match_group_subset = dataset.iloc[match_mask_group, :]

            # find all unique combos of ppm bins within subset
            subset_unique_bins = match_group_subset.ppm_bin.unique()
            subset_unique_bin_codes = str(
                match_group_subset.ppm_bin_codes.unique())
            zipcode = subset_unique_bin_codes

            # assign that list value in a new column to all observations in the match group subset
            dataset.loc[match_group_subset.index,
                        ("polymer_zip_code")] = zipcode

        dataset.polymer_zip_code = dataset.polymer_zip_code.str.replace(
            "[", "", regex=True)
        dataset.polymer_zip_code = dataset.polymer_zip_code.str.replace(
            "]", "", regex=True)

    return dataset, ppm_bin_conversion_dict, polymer_name_conversion_dict


def extract_molecular_weight(x):
    '''Extracts molecular weight from the polymer name string.
    '''
    return [int(substring[:-1]) for substring in x.split('_', -1) if 'k' in substring][0]


def assign_mean_ppms(df):
    '''Assigns an average ppm value to each proton peak index for each polymer to ensure consistency.'''

    df_subset = df[['polymer_name', 'proton_peak_index', 'ppm']].copy()
    key = ['polymer_name', 'proton_peak_index']
    mean_ppms = df_subset.groupby(by=key).mean().round(2)

    # add mean ppms to replace originals
    df = pd.merge(df, mean_ppms, on=key, how='left',
                  suffixes=('_orig', '_avg'))

    # drop originals and duplicates created during join
    df = df.drop(columns='ppm_orig').drop_duplicates()

    return df.rename(columns={'ppm_avg': 'ppm'})


def append_multilabel_zipcodes(df, ppm_bin_conversion_dict):
    '''Multi-label encodes polymer zipcodes into chemical shift fingerprints.

    Parameters:
    ----------
    df: Pandas.Dataframe
        contains a column with the polymer zip code, as generated in 'generate_polymer_zip_codes'

    ppm_bin_conversion_dict: Dictionary
        generated by generate_features, maps encodings between ppm bin intervals and ordinal encodings
    
    Returns:
    -------
    df: Pandas.DataFrame
        now includes the multi label format of ppm bin encodings (chemical shift fingerprints).
    '''

    zip_series = df['polymer_zip_code'].copy()

    # prepare zipcode data types for transformation
    for index, string_value in zip_series.items():
        a_list = string_value.split()
        map_object = map(int, a_list)
        list_of_integers = list(map_object)
        zip_series[index] = np.asarray(list_of_integers)

    # generate the multi-label encodings
    classes = np.array(list(ppm_bin_conversion_dict.keys()))
    mlb = preprocessing.MultiLabelBinarizer(classes=classes)
    zip_mlb = mlb.fit_transform(zip_series)

    # add multi labels back into dataframe
    df = pd.concat([df, pd.DataFrame(zip_mlb, columns=ppm_bin_conversion_dict.values())], axis=1)

    return df
